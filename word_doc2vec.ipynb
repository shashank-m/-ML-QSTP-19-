{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word_doc2vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNR2C3BrLM+l6ZFOgW+jjGU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashank-m/-ML-QSTP-19-/blob/master/word_doc2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkjIIK9BSPHw",
        "colab_type": "text"
      },
      "source": [
        "### Imports and setting up files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfkX688ax5ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import codecs\n",
        "from tqdm import tqdm\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vQSWFbzFq8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5c611b59-d902-43dc-b1db-69f39c91effd"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIgG-tkXu0W2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5845569f-e3f1-4801-ccf1-2b15069974d2"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f37274e3ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFUYtfQ2vWvm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa25270e-f6b0-470a-ee6c-8f7e83e5d81c"
      },
      "source": [
        "\n",
        "is_cuda = torch.cuda.is_available()\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU not available, CPU used\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPmdPOarxzpl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1984a05-be52-444e-f6c7-f4eb0c9d43cf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GStG0DA1Mr-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "filenames=os.listdir(\"/content/drive/My Drive/covid_nlp/2020-03-13/biorxiv_medrxiv/biorxiv_medrxiv\")\n",
        "biorxiv=\"/content/drive/My Drive/covid_nlp/2020-03-13/biorxiv_medrxiv/biorxiv_medrxiv/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LM5Ha1sRScR",
        "colab_type": "text"
      },
      "source": [
        "## ***Preprocessing of abstract***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RQ02m2Z-Q8vp",
        "colab": {}
      },
      "source": [
        "all_files=[json.load(open(biorxiv+filename, 'rb')) for filename in filenames]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBXKyGftMrtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f=all_files[32]\n",
        "abstract=''\n",
        "for dic in f['abstract']:\n",
        "  abstract+=dic['text']\n",
        "  abstract+='\\n'\n",
        "abstract=abstract.lower() # converts all alphabets to lower case."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZAI-MrH-ezyv",
        "colab": {}
      },
      "source": [
        "def preprocess(abstract):\n",
        "  abstract=re.sub(r'[,-?<>:!_+=#$()%^{}|~@;\\'.\"*&[\\]]',' ',abstract) #remove punctuation.\n",
        "  abstract=re.sub(r'\\d+',' ',abstract) # remove digits.\n",
        "  abstract=re.sub(r'\\s+',' ',abstract).strip() # replace multiple white spaces with single whiite space.\n",
        "  return abstract"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoA9vczYdCGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55150239-0bf4-429f-cf9e-cb0901bafba4"
      },
      "source": [
        "abstract=preprocess(abstract)\n",
        "len(abstract)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5602"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXA_8NeXgAAo",
        "colab_type": "text"
      },
      "source": [
        "### **Create train and test data for CBOW model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ofbasEsgw7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNs-8xDUdCDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_tokens=re.findall(r'\\S+',abstract)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1erukxkLf-74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "penta_gram=ngrams(all_tokens,5)\n",
        "for window in penta_gram:\n",
        "  window=list(window)\n",
        "  test_word=window[2]\n",
        "  train_words=window[:2]+window[3:]\n",
        "  train_data.append((train_words,test_word))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3RRe-lsMUco",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d825059-8677-4a75-8560-57f9022ebf56"
      },
      "source": [
        "\n",
        "vocab=set(all_tokens)\n",
        "vocab_size=len(set(all_tokens))\n",
        "word_to_idx={}\n",
        "for i,word in enumerate(vocab):\n",
        "  word_to_idx[word]=i\n",
        "vocab_size  "
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "380"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3BhJo867ytk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24448145-95fe-4b76-912b-7c3e43cabf80"
      },
      "source": [
        "context_data=[]\n",
        "target_data=[]\n",
        "for context,target in train_data:\n",
        "  inputs=torch.LongTensor([word_to_idx[word] for word in context]).view(1,-1) \n",
        "  target_vector=torch.LongTensor([word_to_idx[target]])\n",
        "  context_data.append(inputs)\n",
        "  target_data.append(target_vector)\n",
        "len(target_data)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "834"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doiANoKt9Kqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=torch.cat(context_data,0) # put all training_data into a single tensor so that it can be batched by Dataloader."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d55HfFViAMmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_label=torch.cat(target_data,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liGM4_aPBJIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=32\n",
        "training=TensorDataset(X_train,X_train_label)\n",
        "train_loader=DataLoader(training,batch_size=batch_size,drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pLSxnUHRtSF",
        "colab_type": "text"
      },
      "source": [
        "### CBOW model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q6EcYdVNy1o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e57d224b-e4af-4c65-d453-748409d34f04"
      },
      "source": [
        "class cbow(nn.Module):\n",
        "  def __init__(self,vocab_size,embed_dim,context,hidden_dim,batch_size):\n",
        "    super(cbow,self).__init__()\n",
        "    self.bs=batch_size\n",
        "    self.c=context\n",
        "    self.embeddings=nn.Embedding(vocab_size,embed_dim)\n",
        "    self.linear1=nn.Linear(embed_dim,hidden_dim)\n",
        "    self.linear2=nn.Linear(hidden_dim,vocab_size)\n",
        "    \n",
        "  def forward(self,inputs):\n",
        "    # if inputs.shape[0]==self.bs:\n",
        "      embeds=self.embeddings(inputs)\n",
        "      a_1=F.relu(self.linear1(embeds).sum(axis=1)/self.c)\n",
        "      out=self.linear2(a_1)\n",
        "      return out\n",
        "\n",
        "embed_dim=300\n",
        "\n",
        "model=cbow(vocab_size,embed_dim,4,50,batch_size)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "lr=1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "model.state_dict"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.state_dict of cbow(\n",
              "  (embeddings): Embedding(380, 300)\n",
              "  (linear1): Linear(in_features=300, out_features=50, bias=True)\n",
              "  (linear2): Linear(in_features=50, out_features=380, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q7-Amdneu2v",
        "colab_type": "text"
      },
      "source": [
        "**Note that here training data is generated from only one abstract.We run the cbow model over 50 epochs and it looks like the model is learning something as the loss decreases every epoch. If we can overfit on this small data that means out training process works. We just need to collect more training data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-sN2ccJYreu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "b22fecfd-7961-45ca-9a80-1de52f2c457b"
      },
      "source": [
        "epochs=50\n",
        "for j in range(epochs):\n",
        "  for i,(x,y) in enumerate(train_loader):\n",
        "    model.zero_grad()\n",
        "    out=model(x)\n",
        "\n",
        "    loss=criterion(out,y)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "  print('After epoch {},loss={}'.format(j+1,loss))    "
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After epoch 1,loss=5.885824203491211\n",
            "After epoch 2,loss=5.616886138916016\n",
            "After epoch 3,loss=5.2316460609436035\n",
            "After epoch 4,loss=4.883759498596191\n",
            "After epoch 5,loss=4.592529296875\n",
            "After epoch 6,loss=4.324159622192383\n",
            "After epoch 7,loss=4.058540344238281\n",
            "After epoch 8,loss=3.7785441875457764\n",
            "After epoch 9,loss=3.4769744873046875\n",
            "After epoch 10,loss=3.1627917289733887\n",
            "After epoch 11,loss=2.826920986175537\n",
            "After epoch 12,loss=2.493203639984131\n",
            "After epoch 13,loss=2.1635921001434326\n",
            "After epoch 14,loss=1.8549734354019165\n",
            "After epoch 15,loss=1.5731874704360962\n",
            "After epoch 16,loss=1.3291620016098022\n",
            "After epoch 17,loss=1.1199700832366943\n",
            "After epoch 18,loss=0.9454092383384705\n",
            "After epoch 19,loss=0.7982237339019775\n",
            "After epoch 20,loss=0.6755102276802063\n",
            "After epoch 21,loss=0.5713686347007751\n",
            "After epoch 22,loss=0.48508062958717346\n",
            "After epoch 23,loss=0.41218945384025574\n",
            "After epoch 24,loss=0.3532406985759735\n",
            "After epoch 25,loss=0.30278918147087097\n",
            "After epoch 26,loss=0.2626253068447113\n",
            "After epoch 27,loss=0.22829051315784454\n",
            "After epoch 28,loss=0.20131202042102814\n",
            "After epoch 29,loss=0.1780029833316803\n",
            "After epoch 30,loss=0.15805459022521973\n",
            "After epoch 31,loss=0.14167988300323486\n",
            "After epoch 32,loss=0.1281619817018509\n",
            "After epoch 33,loss=0.11572494357824326\n",
            "After epoch 34,loss=0.10490640252828598\n",
            "After epoch 35,loss=0.0954400971531868\n",
            "After epoch 36,loss=0.08806083351373672\n",
            "After epoch 37,loss=0.08061107993125916\n",
            "After epoch 38,loss=0.0748138427734375\n",
            "After epoch 39,loss=0.06876423954963684\n",
            "After epoch 40,loss=0.06385277211666107\n",
            "After epoch 41,loss=0.05937890708446503\n",
            "After epoch 42,loss=0.05534848943352699\n",
            "After epoch 43,loss=0.05191364139318466\n",
            "After epoch 44,loss=0.048350740224123\n",
            "After epoch 45,loss=0.04543311893939972\n",
            "After epoch 46,loss=0.04277551546692848\n",
            "After epoch 47,loss=0.04021803289651871\n",
            "After epoch 48,loss=0.03794173151254654\n",
            "After epoch 49,loss=0.03588692098855972\n",
            "After epoch 50,loss=0.03389088809490204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdDMH16Sl8HE",
        "colab_type": "text"
      },
      "source": [
        "**As we can see above, our tarin loss almost comes down to zero. This shows the learning process is not an issue. Time to collect more trainig data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUP2eqPYlFwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}